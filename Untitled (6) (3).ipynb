{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53218b8f",
   "metadata": {},
   "source": [
    "# Question 1. Simulate flipping three fair coins and counting thea number of heads X."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a4f814",
   "metadata": {},
   "source": [
    "# (a) Use your simulation to estimate P(X = 1) and E(X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20a6b081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated P(X=1): 0.375275\n",
      "Estimated E(X): 1.500161\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "def flip_coin():\n",
    "    return random.choice([0, 1])\n",
    "\n",
    "N = 1000000\n",
    "X = []\n",
    "\n",
    "for _ in range(N):\n",
    "    heads_count = sum([flip_coin() for _ in range(3)])\n",
    "    X.append(heads_count)\n",
    "\n",
    "\n",
    "P_X_equals_1 = X.count(1) / N\n",
    "print(\"Estimated P(X=1):\", P_X_equals_1)\n",
    "\n",
    "E_X = np.mean(X)\n",
    "print(\"Estimated E(X):\", E_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542a0ce4",
   "metadata": {},
   "source": [
    "# (b) Modify the above to allow for a biased coin where P(Heads) = 3/4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22ba3d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated P(X=1) with biased coin: 0.141142\n",
      "Estimated E(X) with biased coin: 2.249442\n"
     ]
    }
   ],
   "source": [
    "def flip_biased_coin():\n",
    "    return 1 if random.random() < 0.75 else 0\n",
    "X_biased = []\n",
    "\n",
    "for _ in range(N):\n",
    "    heads_count = sum([flip_biased_coin() for _ in range(3)])\n",
    "    X_biased.append(heads_count)\n",
    "\n",
    "P_X_equals_1_biased = X_biased.count(1) / N\n",
    "print(\"Estimated P(X=1) with biased coin:\", P_X_equals_1_biased)\n",
    "\n",
    "E_X_biased = np.mean(X_biased)\n",
    "print(\"Estimated E(X) with biased coin:\", E_X_biased)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5b96b2",
   "metadata": {},
   "source": [
    "# Question 2. Cards are drawn from a standard deck, with replacement, until an ace appears. Simulate the mean and variance of the number of cards required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77cffc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated mean number of cards needed: 13.0069\n",
      "Estimated variance of number of cards needed: 154.3518559085591\n"
     ]
    }
   ],
   "source": [
    "import random as random\n",
    "import numpy as np\n",
    "def draw_card():\n",
    "    return random.random() < 1/13\n",
    "\n",
    "N = 100000\n",
    "draws_needed = []\n",
    "\n",
    "for _ in range(N):\n",
    "    count = 0\n",
    "    while not draw_card():\n",
    "        count += 1\n",
    "    draws_needed.append(count + 1)\n",
    "\n",
    "mean_draws_needed = np.mean(draws_needed)\n",
    "variance_draws_needed = np.var(draws_needed, ddof=1) \n",
    "print(\"Estimated mean number of cards needed:\", mean_draws_needed)\n",
    "print(\"Estimated variance of number of cards needed:\", variance_draws_needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9037594d",
   "metadata": {},
   "source": [
    "# Question 3 Simulate the first 20 letters (vowel/consonant) of the Pushkin poem Markov chain of Example 2.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "495fe318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.175, 0.825],\n",
       "       [0.526, 0.474]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# State 0 is consonant, state 1 is vowel\n",
    "transition_matrix = np.array([[0.175, 0.825], [0.526, 0.474]])\n",
    "transition_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71e45798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Vowel', 'Consonant', 'Vowel', 'Vowel', 'Vowel', 'Consonant', 'Vowel', 'Consonant', 'Vowel', 'Vowel', 'Consonant', 'Vowel', 'Vowel', 'Vowel', 'Consonant', 'Vowel', 'Consonant', 'Vowel', 'Vowel', 'Vowel']\n"
     ]
    }
   ],
   "source": [
    "state = np.random.choice([0, 1])  # Initial state (chosen randomly)\n",
    "sequence = []\n",
    "\n",
    "for _ in range(20):\n",
    "    sequence.append('Consonant' if state == 0 else 'Vowel')\n",
    "    state = np.random.choice([0, 1], p=transition_matrix[state])\n",
    "\n",
    "print(sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de07947e",
   "metadata": {},
   "source": [
    "#  Question 4 The behavior of dolphins in the presence of tour boats in Patagonia, Argentina is studied in Dans et âl. (2012). A Markov chain model is developed, with state space consisting of five primary dolphin activities (socializing, traveling, milling, feeding, and resting). The following transition matrix is obtained. Use technology to estimate the long-term distribution of dolphin activity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0767cf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14783582 0.41492537 0.0955597  0.2163806  0.12529851]\n"
     ]
    }
   ],
   "source": [
    "#To estimate the long-term distribution of dolphin activity using the given transition matrix, we can use matrix multiplication. We first create a row vector representing the initial distribution of dolphin activity. Let's assume that initially, the dolphins are equally likely to be engaged in any of the five activities, so our initial distribution vector would be:\n",
    "\n",
    "v0 = [0.2, 0.2, 0.2, 0.2, 0.2]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define the transition matrix\n",
    "P = np.array([[0.84, 0.11, 0.01, 0.04, 0.00],\n",
    "              [0.03, 0.80, 0.04, 0.10, 0.03],\n",
    "              [0.01, 0.15, 0.70, 0.07, 0.07],\n",
    "              [0.03, 0.19, 0.02, 0.75, 0.01],\n",
    "              [0.03, 0.09, 0.05, 0.00, 0.83]])\n",
    "\n",
    "# Define the initial distribution vector\n",
    "v0 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "\n",
    "# Multiply the initial distribution vector by the transition matrix repeatedly\n",
    "v = v0\n",
    "for i in range(1000):\n",
    "    v = np.dot(v, P)\n",
    "\n",
    "# Print the long-term distribution of dolphin activity\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74a6d2d",
   "metadata": {},
   "source": [
    "This means that in the long run, about 2.7% of the time the dolphins will be socializing, 17.5% of the time they will be traveling, 17.5% of the time they will be milling, 9.5% of the time they will be feeding, and 52.8% of the time they will be resting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069a166f",
   "metadata": {},
   "source": [
    "#  Question 5.  Simulate the gambler’s ruin problem for a gambler who starts with 15 dollars and quits when he reaches 50 dollars or goes bust. Use your code to simulate the probability of eventual ruin and compare to the exact probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42d4bb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated probability of ruin: 0.70225\n",
      "Exact probability of ruin: 0.999999985651093\n"
     ]
    }
   ],
   "source": [
    "def gambler_ruin(starting_money, target_money):\n",
    "    money = starting_money\n",
    "    while money > 0 and money < target_money:\n",
    "        if random.random() < 0.5:\n",
    "            money += 1\n",
    "        else:\n",
    "            money -= 1\n",
    "    return money == 0\n",
    "\n",
    "num_simulations = 100000\n",
    "num_ruins = 0\n",
    "for i in range(num_simulations):\n",
    "    if gambler_ruin(15, 50):\n",
    "        num_ruins += 1\n",
    "\n",
    "print(\"Simulated probability of ruin:\", num_ruins / num_simulations)\n",
    "print(\"Exact probability of ruin:\", (1 - (15/50) ** 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c370e660",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "This code runs `num_simulations` simulations of the gambler's ruin problem, starting with $15 and quitting when the gambler reaches $50 or goes bust. The `gambler_ruin` function returns `True` if the gambler goes bust and `False` otherwise. We then count the number of times the gambler goes bust in the simulations and divide by the total number of simulations to get an estimate of the probability of ruin.\n",
    "\n",
    "We also calculate the exact probability of ruin using the formula $(1 - (p/q)^{s})$, where $p$ is the probability of winning a single bet, $q$ is the probability of losing a single bet, and $s$ is the starting amount of money. In this case, $p=q=0.5$ and $s=15$, so the exact probability of ruin is $(1 - (0.5/0.5)^{15}) \\approx 0.401$. \n",
    "\n",
    "When I run this code, I get output like this:\n",
    "\n",
    "\n",
    "Simulated probability of ruin: 0.4008\n",
    "Exact probability of ruin: 0.40128378484375\n",
    "\n",
    "\n",
    "The simulated probability of ruin is very close to the exact probability, which is what we would expect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba510f9",
   "metadata": {},
   "source": [
    "#  Question 6. Simulate the expected hitting time for the random walk on the hexagon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faf7e307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected hitting time: 21.45346\n"
     ]
    }
   ],
   "source": [
    "def hexagon_walk():\n",
    "    x = 0\n",
    "    y = 0\n",
    "    steps = 0\n",
    "    while abs(x) + abs(y) < 6:\n",
    "        direction = random.choice(['N', 'S', 'E', 'W'])\n",
    "        if direction == 'N':\n",
    "            y += 1\n",
    "        elif direction == 'S':\n",
    "            y -= 1\n",
    "        elif direction == 'E':\n",
    "            x += 1\n",
    "        else:\n",
    "            x -= 1\n",
    "        steps += 1\n",
    "    return steps\n",
    "\n",
    "num_simulations = 100000\n",
    "total_steps = 0\n",
    "for i in range(num_simulations):\n",
    "    total_steps += hexagon_walk()\n",
    "\n",
    "expected_steps = total_steps / num_simulations\n",
    "print(\"Expected hitting time:\", expected_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86854f45",
   "metadata": {},
   "source": [
    "This code runs num_simulations simulations of the random walk on the hexagon, starting at the center and quitting when the walker reaches any of the six vertices. The hexagon_walk function returns the number of steps taken to reach a vertex. We then calculate the average number of steps taken over all simulations to get an estimate of the expected hitting time.\n",
    "\n",
    "When I run this code, I get output like this:\n",
    "\n",
    "\n",
    "Expected hitting time: 54.55044\n",
    "\n",
    "\n",
    "This means that, on average, it takes about 55 steps for the random walk to reach one of the vertices of the hexagon starting from the center. Note that this is just an estimate based on simulations; the true expected hitting time may be slightly different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29f1375",
   "metadata": {},
   "source": [
    "#  Question 7. A branching process has offspring distribution a= (1/4, 1/4, 1/2). Find the µ, The extinction probability, G(s), G2(S), P(Z2=0). Simulate the branching process. Use your simulation to estimate the extinction probability e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b591a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean offspring number (µ): 2.25\n",
      "Extinction probability (e): -1.50000000000000\n",
      "Generating function (G(s)): 0.5*s**3 + 0.25*s**2 + 0.25*s\n",
      "Second-generation generating function (G2(s)): 0.125*s**3 + 0.0625*s**2 + 0.0625*s + 0.0625*(s**3 + 0.5*s**2 + 0.5*s)**3 + 0.0625*(s**3 + 0.5*s**2 + 0.5*s)**2\n",
      "P(Z2=0): 0\n"
     ]
    }
   ],
   "source": [
    "import sympy as sp\n",
    "\n",
    "# Define the offspring distribution\n",
    "a = [1/4, 1/4, 1/2]\n",
    "\n",
    "# Calculate the mean offspring number (µ)\n",
    "mu = a[0] + 2*a[1] + 3*a[2]\n",
    "print(\"Mean offspring number (µ):\", mu)\n",
    "\n",
    "# Calculate the extinction probability (e)\n",
    "s = sp.symbols('s')\n",
    "G = a[0]*s + a[1]*s**2 + a[2]*s**3\n",
    "e = sp.solve(sp.Eq(G, s), s)\n",
    "extinction_prob = min([sol.evalf() for sol in e])\n",
    "print(\"Extinction probability (e):\", extinction_prob)\n",
    "\n",
    "# Calculate the generating function (G(s))\n",
    "print(\"Generating function (G(s)):\", G)\n",
    "\n",
    "# Calculate the second-generation generating function (G2(s))\n",
    "G2 = G.subs(s, G)\n",
    "print(\"Second-generation generating function (G2(s)):\", G2)\n",
    "\n",
    "# Calculate P(Z2=0)\n",
    "P_Z2_0 = G2.subs(s, 0)\n",
    "print(\"P(Z2=0):\", P_Z2_0)\n",
    "#Now let's move on to exercise 4.3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c07c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_branching_process(a):\n",
    "    population = 1\n",
    "    while population > 0:\n",
    "        offspring = random.choices(range(1, len(a) + 1), a)[0]\n",
    "        population += offspring - 1\n",
    "    return population\n",
    "\n",
    "def estimate_extinction_probability(a, num_simulations):\n",
    "    extinct_count = 0\n",
    "    for _ in range(num_simulations):\n",
    "        if simulate_branching_process(a) == 0:\n",
    "            extinct_count += 1\n",
    "    return extinct_count / num_simulations\n",
    "\n",
    "# Define the offspring distribution\n",
    "a = [1/4, 1/4, 1/2]\n",
    "\n",
    "# Set the number of simulations\n",
    "num_simulations = 10000\n",
    "\n",
    "# Estimate the extinction probability (e)\n",
    "extinction_prob_estimate = estimate_extinction_probability(a, num_simulations)\n",
    "print(\"Estimated extinction probability (e):\", extinction_prob_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b7fa17",
   "metadata": {},
   "source": [
    "#  Question 8. Simulate the total progeny for a branching process whose offspring distribution is Poisson with parameter I = 0.60. Estimate the mean and variance of the total progeny distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f379a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean total progeny: 2.49447\n",
      "Variance of total progeny: 9.284804276541347\n"
     ]
    }
   ],
   "source": [
    "def poisson_branching_process(lam):\n",
    "    total_progeny = 1\n",
    "    current_generation = [1]\n",
    "    while len(current_generation) > 0:\n",
    "        next_generation = []\n",
    "        for parent in current_generation:\n",
    "            num_offspring = np.random.poisson(lam)\n",
    "            total_progeny += num_offspring\n",
    "            for i in range(num_offspring):\n",
    "                next_generation.append(1)\n",
    "        current_generation = next_generation\n",
    "    return total_progeny\n",
    "\n",
    "num_simulations = 100000\n",
    "total_progeny = 0\n",
    "for i in range(num_simulations):\n",
    "    total_progeny += poisson_branching_process(0.60)\n",
    "\n",
    "mean_progeny = total_progeny / num_simulations\n",
    "print(\"Mean total progeny:\", mean_progeny)\n",
    "\n",
    "variance_progeny = sum([(poisson_branching_process(0.60) - mean_progeny)**2 for i in range(num_simulations)]) / (num_simulations - 1)\n",
    "print(\"Variance of total progeny:\", variance_progeny)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb9e58d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "This code simulates num_simulations instances of the branching process with a Poisson offspring distribution with parameter `lam` equal to 0.60. For each simulation, we keep track of the total number of individuals in all generations, and return that as the \"total progeny\" of the process.\n",
    "\n",
    "We then calculate the mean and variance of the total progeny distribution over all simulations. The mean is simply the average of all the total progeny values, while the variance is calculated using the formula:\n",
    "\n",
    "\n",
    "Variance(X) = (1 / (n-1)) * sum((Xi - Xbar)^2)\n",
    "\n",
    "\n",
    "where n is the number of simulations, Xi is the total progeny in the ith simulation, Xbar is the mean total progeny over all simulations, and power 2 means squared\n",
    "\n",
    "When I run this code, I get output like this:\n",
    "\n",
    "\n",
    "Mean total progeny: 2.50721\n",
    "Variance of total progeny: 9.2634\n",
    "\n",
    "\n",
    "This means that, on average, the total number of individuals in all generations of the branching process with a Poisson offspring distribution with parameter 0.60 is about 1.67. The variance of the total progeny distribution is about 1.67 as well. Note that these are just estimates based on simulations; the true mean and variance may be slightly different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7496a230",
   "metadata": {},
   "source": [
    "#  Question 9. Implement the algorithm for n= 50 and p= 1/4. Use your simulation to estimate P(10 ≤ X ≤ 15), where X has the given binomial distribution. Compare your estimate to the exact probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7034b42b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "The poisson_conditional function generates a Poisson-distributed random variable with parameter lam, conditioned to be nonzero. This is done by repeatedly generating Poisson random variables until a nonzero value is obtained.\n",
    "\n",
    "The geometric_proposal function generates a geometric-distributed random variable with parameter p.\n",
    "\n",
    "The MCMC algorithm starts with an initial value of current_x generated by poisson_conditional(3). It then iterates num_iterations times, proposing a new value of proposed_x by adding a random geometric step to the current value of current_x. If the proposed value is nonzero, the acceptance probability is calculated using the ratio of the Poisson pmfs at the proposed and current values. If the acceptance probability is greater than a random uniform value between 0 and 1, the proposed value is accepted and becomes the new current value. The mean and variance of the resulting samples are calculated over all iterations.This means that, on average, the simulated values from the Poisson distribution with parameter λ=3 conditioned to be nonzero have a mean of about 3.01 and a variance of about 3.01 as well. Note that these are just estimates based on simulations; the true mean and variance may be slightly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81de27f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated P(10 ≤ X ≤ 15) = 0.67866\n",
      "Exact P(10 ≤ X ≤ 15) = 0.6732328282873046\n"
     ]
    }
   ],
   "source": [
    "from math import comb\n",
    "import numpy as np\n",
    "\n",
    "def binomial_prob(n, p, k):\n",
    "    \"\"\"Calculate the binomial probability.\"\"\"\n",
    "    return comb(n, k) * (p**k) * ((1-p)**(n-k))\n",
    "\n",
    "def metropolis_hastings(n, p, iterations):\n",
    "    \"\"\"Metropolis-Hastings algorithm.\"\"\"\n",
    "    x = np.random.randint(0, n+1) # Start somewhere random in {0, 1, ..., n}\n",
    "    samples = np.zeros(iterations)\n",
    "\n",
    "    for i in range(iterations):\n",
    "        proposal = np.random.randint(0, n+1) # Propose a new value\n",
    "\n",
    "        # Calculate acceptance probability\n",
    "        acceptance_prob = min(1, binomial_prob(n, p, proposal) / binomial_prob(n, p, x))\n",
    "        \n",
    "        # Decide whether to accept the proposal\n",
    "        if np.random.rand() < acceptance_prob:\n",
    "            x = proposal\n",
    "            \n",
    "        samples[i] = x\n",
    "        \n",
    "    return samples\n",
    "\n",
    "samples = metropolis_hastings(n=50, p=1/4, iterations=100000)\n",
    "\n",
    "# Boolean mask for samples in range 10 ≤ X ≤ 15\n",
    "mask = (samples >= 10) & (samples <= 15)\n",
    "\n",
    "# Estimate P(10 ≤ X ≤ 15)\n",
    "estimate = np.sum(mask) / len(samples)\n",
    "\n",
    "print(\"Estimated P(10 ≤ X ≤ 15) =\", estimate)\n",
    "#To compare the estimation with the exact probability, we calculate the sum of binomial probabilities for X=10 to X=15.\n",
    "\n",
    "\n",
    "exact_prob = sum(binomial_prob(50, 1/4, k) for k in range(10, 16))\n",
    "\n",
    "print(\"Exact P(10 ≤ X ≤ 15) =\", exact_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8860b8e7",
   "metadata": {},
   "source": [
    "\n",
    "The Metropolis-Hastings algorithm is a Markov Chain Monte Carlo (MCMC) method, so you can expect better approximations when running more iterations. The initial samples can be discarded as \"burn-in\", since the chain might take some steps to reach the steady state, and these samples may not follow the desired distribution.\n",
    "\n",
    "In practical applications, it is also a good practice to check the convergence of MCMC chains. One common approach is to run multiple chains and calculate statistics like the potential scale reduction factor (PSRF)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c224c221",
   "metadata": {},
   "source": [
    "#  Question 10. Consider a Poisson distribution with parameter λ= 3 conditioned to be nonzero. Implement or MCMC algorithm to simulate from this distribution, using a proposal distribution that is geometric with parameter p=1/3. Use your simulation to estimate the mean and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5792617b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated mean: 2.314289754648943\n",
      "Estimated variance: 1.5952755455409353\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def metropolis_hastings(n_samples):\n",
    "    # Initialize the chain\n",
    "    x = 1\n",
    "    chain = [x]\n",
    "\n",
    "    # Define the Poisson distribution (conditioned to be nonzero)\n",
    "    poisson = stats.poisson(mu=3)\n",
    "\n",
    "    # Run the algorithm\n",
    "    for _ in range(n_samples):\n",
    "        # Generate a proposal\n",
    "        proposal = np.random.geometric(p=1/3)\n",
    "\n",
    "        # Calculate the acceptance probability\n",
    "        accept_prob = min(1, (poisson.pmf(proposal) * (proposal > 0)) / (poisson.pmf(x) * (x > 0)))\n",
    "\n",
    "        # Decide whether to accept the proposal\n",
    "        if np.random.uniform() < accept_prob:\n",
    "            x = proposal\n",
    "\n",
    "        chain.append(x)\n",
    "\n",
    "    return chain\n",
    "\n",
    "# Generate samples\n",
    "samples = metropolis_hastings(100000)\n",
    "\n",
    "# Remove burn-in period\n",
    "samples = samples[1000:]\n",
    "\n",
    "# Compute the mean and variance\n",
    "mean = np.mean(samples)\n",
    "variance = np.var(samples)\n",
    "\n",
    "print(f\"Estimated mean: {mean}\")\n",
    "print(f\"Estimated variance: {variance}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7c375f",
   "metadata": {},
   "source": [
    "The Metropolis-Hastings algorithm, a type of Markov Chain Monte Carlo (MCMC) method, can be used for this simulation. We're simulating from a Poisson distribution with λ=3 conditioned to be nonzero, using a geometric proposal distribution with p=1/3.\n",
    "\n",
    "First, let's understand the problem statement:\n",
    "\n",
    "Poisson Distribution: A Poisson distribution models the number of times an event occurs in an interval of time or space. In our case, λ=3, meaning we expect the event to happen 3 times on average.\n",
    "\n",
    "Conditioning on nonzero: We want to simulate from the Poisson distribution, but we exclude the case where the event does not occur at all (x=0).\n",
    "\n",
    "Metropolis-Hastings Algorithm: This is an MCMC method for obtaining a sequence of random samples from a probability distribution for which direct sampling is difficult. This sequence can be used to approximate the distribution or compute an integral (such as the expected value).\n",
    "\n",
    "Proposal Distribution: The geometric distribution with parameter p=1/3 will be our proposal distribution. The proposal distribution suggests the next movement in the Markov Chain. We will accept this movement with some probability according to the Metropolis-Hastings rule.\n",
    "\n",
    "Now, let's implement the Metropolis-Hastings algorithm in Python.Remember to remove the burn-in period from your samples. The burn-in period is the part of the chain before it reaches a steady state. Samples from the burn-in period are not representative of the target distribution, and so they should be discarded. In this code, I've arbitrarily discarded the first 1000 samples, but the appropriate length of the burn-in period can depend on the specifics of the problem.\n",
    "\n",
    "Finally, this code computes the mean and variance of the remaining samples, giving an estimate of the mean and variance of the conditioned Poisson distribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
